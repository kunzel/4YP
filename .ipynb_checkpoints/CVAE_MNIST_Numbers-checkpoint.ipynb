{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/lorenzosintini/4YP/blob/master/CVAE_MNIST_Numbers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C8VH0HaF0eaI"
   },
   "source": [
    "#### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "887mv3aj0eaL"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    # %tensorflow_version only exists in Colab.\n",
    "    %tensorflow_version 2.x\n",
    "except Exception:\n",
    "    pass\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sUEIvx3I0eaT"
   },
   "source": [
    "#### Import Data (and select part of it only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tkekihPQ0eaU"
   },
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "pick_class = True\n",
    "crop_input = False\n",
    "class_to_pick = 2\n",
    "data_inputs = 1000\n",
    "\n",
    "def pick_class(x_train, y_train, class_n):\n",
    "    new_x_train=x_train[y_train == class_n]\n",
    "    new_y_train=y_train[y_train == class_n]\n",
    "    return new_x_train, new_y_train\n",
    "\n",
    "if pick_class:\n",
    "    x_train, y_train = pick_class(x_train, y_train, class_to_pick)\n",
    "\n",
    "if crop_input:\n",
    "    x_train = x_train[0:data_inputs]\n",
    "    y_train = y_train[0:data_inputs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lv1qfPcr0eaZ"
   },
   "source": [
    "#### Define Data Size and Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SXK5XnqV0eab"
   },
   "outputs": [],
   "source": [
    "# INPUT DATA\n",
    "class_names = ['Zero','One', 'Two', 'Three', 'Four', 'Five','Six', 'Seven', 'Eight', 'Nine']\n",
    "N_image_channels = 1\n",
    "\n",
    "N_train = len(y_train)\n",
    "N_test = len(y_test)\n",
    "N_class = len(class_names)\n",
    "image_shape = x_train.shape[1:3]\n",
    "input_range = np.amax(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BlFAjQiU0eae"
   },
   "source": [
    "#### Plot images from set (random or in order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "colab_type": "code",
    "id": "y3udHn4E0eag",
    "outputId": "088502b1-4c8d-4853-8599-8ff93ad01906"
   },
   "outputs": [],
   "source": [
    "def plot_images(x_train, y_train, figures_to_plot=10, pick_random=False, include_labels=True):\n",
    "    n_rows = np.ceil(figures_to_plot/10)\n",
    "    plot = plt.figure(figsize=[20,2*n_rows])\n",
    "    for i in range(figures_to_plot):\n",
    "        if pick_random: \n",
    "            pic_n = random.randint(0,len(x_train))\n",
    "        else: pic_n = i\n",
    "        plt.subplot(n_rows,10,i+1)\n",
    "        plt.xticks([]); plt.yticks([])\n",
    "        plt.imshow(x_train[pic_n], cmap=plt.cm.binary)\n",
    "        if include_labels:\n",
    "            plt.xlabel(y_train[pic_n])\n",
    "    plt.show()\n",
    "\n",
    "plot_images(x_train, y_train, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aYGjpOyi0eam"
   },
   "source": [
    "#### Pre-Proces Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 160
    },
    "colab_type": "code",
    "id": "EdMZHoBl0ean",
    "outputId": "b47fd4fd-dd3a-400c-9020-53e2d224b126"
   },
   "outputs": [],
   "source": [
    "train_images = x_train/input_range\n",
    "test_images = x_test/input_range\n",
    "\n",
    "def set_pixels_binary(images):\n",
    "    images[images >= 0.5] = 1.0\n",
    "    images[images < 0.5] = 0.0\n",
    "    return images\n",
    "\n",
    "train_images = set_pixels_binary(train_images)\n",
    "test_images = set_pixels_binary(test_images)\n",
    "train_labels = y_train\n",
    "test_labels = y_test\n",
    "\n",
    "print(np.shape(train_images))\n",
    "plot_images(train_images, train_labels, 10)\n",
    "\n",
    "train_images = train_images.reshape(N_train, image_shape[0], image_shape[1], N_image_channels).astype('float32')\n",
    "test_images = test_images.reshape(N_test, image_shape[0], image_shape[1], N_image_channels).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qIBflbVS0eas"
   },
   "source": [
    "#### Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S1KptUf00eau"
   },
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_images)).shuffle(N_train).batch(batch_size)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_images)).shuffle(N_test).batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RXAUM1Hh0ea0"
   },
   "source": [
    "#### Create Variational Autoencoder (VAE) Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 561
    },
    "colab_type": "code",
    "id": "oiLqehle0ea2",
    "outputId": "c4c04b5f-97c1-4106-c0ef-cb3a4f40e16a"
   },
   "outputs": [],
   "source": [
    "class CVAE(tf.keras.Model):\n",
    "    def __init__(self, z_size):\n",
    "        super(CVAE, self).__init__()\n",
    "        self.z_size = z_size\n",
    "        self.encoder_nn = tf.keras.models.Sequential([ \n",
    "                          tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
    "                          tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "                          tf.keras.layers.Flatten(),\n",
    "                          tf.keras.layers.Dense(z_size*2)\n",
    "                          ])\n",
    "\n",
    "        self.decoder_nn = tf.keras.models.Sequential([\n",
    "                          tf.keras.layers.Dense(units=24*24*64, activation='relu', input_shape=(z_size,)),\n",
    "                          tf.keras.layers.Reshape(target_shape=(24, 24, 64)),\n",
    "                          tf.keras.layers.Conv2DTranspose(32, (3,3), activation='relu'),\n",
    "                          tf.keras.layers.Conv2DTranspose(1, (3,3)),\n",
    "                          ])\n",
    "    @tf.function\n",
    "    def encode(self, x):\n",
    "        encoder_nn_output = self.encoder_nn(x)\n",
    "        z_mean, z_logvar = tf.split(encoder_nn_output, num_or_size_splits=2, axis=1)\n",
    "        return z_mean, z_logvar\n",
    "\n",
    "    def reparameterize(self, z_mean, z_logvar):\n",
    "        epsilon = tf.random.normal(shape=z_mean.shape)\n",
    "        z_sampled = epsilon * tf.exp(z_logvar * 0.5) + z_mean\n",
    "        return z_sampled\n",
    "    \n",
    "    def decode(self, z):\n",
    "        pixel_output = self.decoder_nn(z)\n",
    "        pixel_prob = tf.math.sigmoid(pixel_output)\n",
    "        return pixel_prob\n",
    "\n",
    "z_size = 30\n",
    "model = CVAE(z_size)\n",
    "model.encoder_nn.summary()\n",
    "model.decoder_nn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ruRl4I4K0ea8"
   },
   "source": [
    "#### Define the loss function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y1QqvVSV0ea-"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def calculate_ELBO(model, x):\n",
    "    z_mean, z_logvar = model.encode(x)\n",
    "    z = model.reparameterize(z_mean, z_logvar)\n",
    "    \n",
    "    pixel_prob = model.decode(z)\n",
    "    \n",
    "    logpx_z_pixels = tf.math.log(pixel_prob + 1e-10)*x + tf.math.log(1-pixel_prob + 1e-10)*(1-x)\n",
    "    logpx_z_images = tf.reduce_sum(logpx_z_pixels, axis=[1, 2, 3])\n",
    "    logpx_z = tf.reduce_mean (logpx_z_images)\n",
    "    \n",
    "    KL_parameters = -0.5 * (1 + z_logvar - (z_mean ** 2.0) - tf.exp(z_logvar))\n",
    "    KL_vectors = tf.reduce_sum(KL_parameters, axis=1)\n",
    "    KL = tf.reduce_mean(KL_vectors)\n",
    "    \n",
    "    ELBO = (logpx_z - KL)\n",
    "    \n",
    "    return -ELBO #Negative because we want to maximise it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vLIG3YRm0ebE"
   },
   "source": [
    "#### Define the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n5eaPpso0ebG"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NvoBcADVjvek"
   },
   "source": [
    "#### Define loss metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DhYcUUvYjven"
   },
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VngH-amb0ebM"
   },
   "source": [
    "#### Define train and test steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dNN76Ed_0ebO"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(model, x, optimizer):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = calculate_ELBO(model, x)\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "        train_loss(loss)\n",
    "        \n",
    "@tf.function\n",
    "def test_step(model, x, optimizer):\n",
    "    loss = calculate_ELBO(model, x)\n",
    "    test_loss(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bzdhLrrs0ebT"
   },
   "source": [
    "#### Generate random image from latent vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JUG20q7J0ebW"
   },
   "outputs": [],
   "source": [
    "def generate_images(model, z_random, figures_to_plot):\n",
    "    generated_prob = model.decode(z_random)\n",
    "    generated_prob = np.squeeze(generated_prob, axis=3)\n",
    "    plot_images(generated_prob, _, figures_to_plot=figures_to_plot, include_labels=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b4MLsF1E0ebZ"
   },
   "source": [
    "#### Train the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "pi8CDE0g0eba",
    "outputId": "a28c4bc6-9aad-4f5a-f368-a6edbc50a5c2"
   },
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "plots_per_epoch = 10\n",
    "z_random = tf.random.normal(shape=[plots_per_epoch, z_size])\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i, train_x in enumerate(train_dataset): \n",
    "        sys.stdout.write('\\r'+'Epoch {} progress (%): {}'.format(epoch+1,100*(i+1)/(np.ceil(N_train/batch_size))))\n",
    "        sys.stdout.flush()\n",
    "        train_step(model, train_x, optimizer)\n",
    "\n",
    "    for i, test_x in enumerate(test_dataset):\n",
    "        test_step(model, test_x, optimizer)\n",
    "    \n",
    "    print('\\nTrain ELBO: {};\\nTest ELBO: {};\\nGenerated images:'.format(-train_loss.result(), -test_loss.result()))\n",
    "    \n",
    "    generate_images(model, z_random, plots_per_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "94NCuC4D0ebd"
   },
   "source": [
    "#### Reconstruct image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "id": "jz0G3WmQD2vI",
    "outputId": "b434270f-9529-4bd1-ea80-7526b66e2b3f"
   },
   "outputs": [],
   "source": [
    "def reconstruct_images(range1, range2):\n",
    "    images_to_pick = range(range1,range2)\n",
    "    y = x_train[images_to_pick]\n",
    "    x = train_images[images_to_pick]\n",
    "    loss = np.empty([len(images_to_pick)])\n",
    "\n",
    "    z_mean, z_logvar = model.encode(x)\n",
    "    z = model.reparameterize(z_mean, z_logvar)\n",
    "    pixel_output = model.decode(z)\n",
    "    pixel_prob = tf.math.sigmoid(pixel_output)\n",
    "    pixel_prob = np.squeeze(pixel_prob, axis=3)\n",
    "\n",
    "    for i in range(len(images_to_pick)):\n",
    "        loss[i] = calculate_ELBO(model,x[i:i+1])\n",
    "\n",
    "    loss = loss.astype('float16')\n",
    "    plot_images(y, _, figures_to_plot=len(images_to_pick), include_labels=False)\n",
    "    plot_images(pixel_prob, -loss, figures_to_plot=len(images_to_pick), include_labels=True)\n",
    "\n",
    "reconstruct_images(0,5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nOgW1CZIjvfG"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "name": "CVAE_MNIST_Numbers.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
