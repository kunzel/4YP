{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "CVAE_MNIST_Numbers.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lorenzosintini/4YP/blob/master/VAE_Convolutional.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "C8VH0HaF0eaI"
      },
      "source": [
        "#### Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "887mv3aj0eaL",
        "colab": {}
      },
      "source": [
        "try:\n",
        "    # %tensorflow_version only exists in Colab.\n",
        "    %tensorflow_version 2.x\n",
        "except Exception:\n",
        "    pass\n",
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import time\n",
        "import os\n",
        "import sys\n",
        "from IPython.display import clear_output\n",
        "import os\n",
        "tf.autograph.set_verbosity(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sUEIvx3I0eaT"
      },
      "source": [
        "#### Import Data and plot it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tkekihPQ0eaU",
        "colab": {}
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "class_names = ['Zero','One', 'Two', 'Three', 'Four', 'Five','Six', 'Seven', 'Eight', 'Nine']\n",
        "N_image_channels = 1\n",
        "N_class = len(class_names)\n",
        "image_shape = x_train.shape[1:3]\n",
        "input_range = np.amax(x_train)\n",
        "\n",
        "def plot_images(x_train, y_train, figures_to_plot, pick_random=False, include_labels=True):\n",
        "    n_rows = np.ceil((figures_to_plot[1])/10)\n",
        "    plot = plt.figure(figsize=[20,2*n_rows])\n",
        "    for i in range(figures_to_plot[0],figures_to_plot[1]):\n",
        "        if pick_random: \n",
        "            pic_n = random.randint(0,len(x_train))\n",
        "        else: pic_n = i\n",
        "        plt.subplot(n_rows,10,i+1)\n",
        "        plt.xticks([]); plt.yticks([])\n",
        "        plt.imshow(x_train[pic_n], cmap=plt.cm.binary)\n",
        "        if include_labels:\n",
        "            plt.xlabel(y_train[pic_n])\n",
        "    plt.show()\n",
        "\n",
        "plot_images(x_train, y_train, [0,10])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lv1qfPcr0eaZ"
      },
      "source": [
        "#### Select data, pre-process it and create dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SXK5XnqV0eab",
        "colab": {}
      },
      "source": [
        "def pick_class(x, y, class_n):\n",
        "    pics = (y == class_n[0])\n",
        "    for i in range(len(class_n)-1):\n",
        "      pics = pics + (y == class_n[i+1])\n",
        "    new_x = x[pics]\n",
        "    new_y = y[pics]\n",
        "    return new_x, new_y\n",
        "\n",
        "def set_pixels_binary(images):\n",
        "    images = images/input_range\n",
        "    images[images >= 0.5] = 1.0\n",
        "    images[images < 0.5] = 0.0\n",
        "    return images\n",
        "\n",
        "def make_categorical(y):\n",
        "    y_cat = tf.keras.utils.to_categorical(y)\n",
        "    return y_cat\n",
        "\n",
        "def cut_data(data, data_number):\n",
        "    data = data[0:data_number]\n",
        "    return data\n",
        "\n",
        "def setup_dataset(x_train, y_train, x_test, y_test, chosen_classes=[0,1,2,3,4,5,6,7,8,9], data_number = -1):\n",
        "  x_train, y_train = pick_class(x_train, y_train, chosen_classes)\n",
        "  x_test, y_test = pick_class(x_test, y_test, chosen_classes)\n",
        "  \n",
        "  x_train = cut_data(x_train, data_number)\n",
        "  y_train = cut_data(y_train, data_number)\n",
        "\n",
        "  train_images = set_pixels_binary(x_train)\n",
        "  test_images = set_pixels_binary(x_test)\n",
        "\n",
        "  train_images = train_images.reshape(len(y_train), image_shape[0], image_shape[1], N_image_channels).astype('float32')\n",
        "  test_images = test_images.reshape(len(y_test), image_shape[0], image_shape[1], N_image_channels).astype('float32')\n",
        "\n",
        "  batch_size = 100\n",
        "  train_dataset = tf.data.Dataset.from_tensor_slices((train_images)).shuffle(len(y_train)).batch(batch_size)\n",
        "  test_dataset = tf.data.Dataset.from_tensor_slices((test_images)).shuffle(len(y_test)).batch(batch_size)\n",
        "  return x_train, y_train, x_test, y_test, train_dataset, test_dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RXAUM1Hh0ea0"
      },
      "source": [
        "#### Create Variational Autoencoder (VAE) Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oiLqehle0ea2",
        "colab": {}
      },
      "source": [
        "class CVAE(tf.keras.Model):\n",
        "    def __init__(self, z_size):\n",
        "        super(CVAE, self).__init__()\n",
        "        self.z_size = z_size\n",
        "        self.encoder_nn = tf.keras.models.Sequential([ \n",
        "                          tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
        "                          tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "                          tf.keras.layers.Flatten(),\n",
        "                          tf.keras.layers.Dense(z_size*2)\n",
        "                          ])\n",
        "\n",
        "        self.decoder_nn = tf.keras.models.Sequential([\n",
        "                          tf.keras.layers.Dense(units=24*24*64, activation='relu', input_shape=(z_size,)),\n",
        "                          tf.keras.layers.Reshape(target_shape=(24, 24, 64)),\n",
        "                          tf.keras.layers.Conv2DTranspose(32, (3,3), activation='relu'),\n",
        "                          tf.keras.layers.Conv2DTranspose(1, (3,3)),\n",
        "                          ])\n",
        "\n",
        "    def encode(self, x):\n",
        "        encoder_nn_output = self.encoder_nn(x)\n",
        "        z_mean, z_logvar = tf.split(encoder_nn_output, num_or_size_splits=2, axis=1)\n",
        "        return z_mean, z_logvar\n",
        "\n",
        "    def reparameterize(self, z_mean, z_logvar):\n",
        "        epsilon = tf.random.normal(shape=z_mean.shape)\n",
        "        z_sampled = epsilon * tf.exp(z_logvar * 0.5) + z_mean\n",
        "        return z_sampled\n",
        "      \n",
        "\n",
        "    def decode(self, z):\n",
        "        pixel_output = self.decoder_nn(z)\n",
        "        pixel_prob = tf.math.sigmoid(pixel_output)\n",
        "        return pixel_prob"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ruRl4I4K0ea8"
      },
      "source": [
        "#### Define the loss function "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Y1QqvVSV0ea-",
        "colab": {}
      },
      "source": [
        "def calculate_ELBO(model, x):\n",
        "    z_mean, z_logvar = model.encode(x)\n",
        "    z = model.reparameterize(z_mean, z_logvar)\n",
        "    \n",
        "    pixel_prob = model.decode(z)\n",
        "    \n",
        "    logpx_z_pixels = tf.math.log(pixel_prob + 1e-10)*x + tf.math.log(1-pixel_prob + 1e-10)*(1-x)\n",
        "    logpx_z_images = tf.reduce_sum(logpx_z_pixels, axis=[1, 2, 3])\n",
        "    logpx_z = tf.reduce_mean (logpx_z_images)\n",
        "    \n",
        "    KL_parameters = -0.5 * (1 + z_logvar - (z_mean ** 2.0) - tf.exp(z_logvar))\n",
        "    KL_vectors = tf.reduce_sum(KL_parameters, axis=1)\n",
        "    KL = tf.reduce_mean(KL_vectors)\n",
        "    \n",
        "    ELBO = (logpx_z - KL)\n",
        "    \n",
        "    return -ELBO #Negative because we want to maximise it"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vLIG3YRm0ebE"
      },
      "source": [
        "#### Define the optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "n5eaPpso0ebG",
        "colab": {}
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NvoBcADVjvek"
      },
      "source": [
        "#### Define loss metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DhYcUUvYjven",
        "colab": {}
      },
      "source": [
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "test_loss = tf.keras.metrics.Mean(name='test_loss')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VngH-amb0ebM"
      },
      "source": [
        "#### Define train and test steps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dNN76Ed_0ebO",
        "colab": {}
      },
      "source": [
        "def train_step(model, x, optimizer):\n",
        "    with tf.GradientTape() as tape:\n",
        "        loss = calculate_ELBO(model, x)\n",
        "        gradients = tape.gradient(loss, model.trainable_variables)\n",
        "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "        train_loss(loss)\n",
        "\n",
        "def test_step(model, x, optimizer):\n",
        "    loss = calculate_ELBO(model, x)\n",
        "    test_loss(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6eTvDNOZGjW",
        "colab_type": "text"
      },
      "source": [
        "#### Generate random image from latent vector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JUG20q7J0ebW",
        "colab": {}
      },
      "source": [
        "def generate_images(model, z_random, figures_to_plot):\n",
        "    generated_prob = model.decode(z_random)\n",
        "    generated_prob = np.squeeze(generated_prob, axis=3)\n",
        "    plot_images(generated_prob, _, figures_to_plot, include_labels=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SprYQb15_4ta",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_test_dataset(model, train_dataset, test_dataset, epochs, generate=True):\n",
        "  plots_per_epoch = 10\n",
        "  z_random = tf.random.normal(shape=[plots_per_epoch, z_size])\n",
        "  \n",
        "  test_ELBO = []\n",
        "  train_ELBO = []\n",
        "  epoch_number = []  \n",
        "  for epoch in range(epochs):\n",
        "    print('Epoch {}'.format(epoch))\n",
        "    for train_x in train_dataset: \n",
        "      train_step(model, train_x, optimizer)\n",
        "  \n",
        "    for test_x in test_dataset:\n",
        "      test_step(model, test_x, optimizer)\n",
        "    \n",
        "    test_ELBO.append(-test_loss.result())\n",
        "    train_ELBO.append(-train_loss.result())\n",
        "    epoch_number.append(epoch)\n",
        "    \n",
        "    clear_output()\n",
        "    if generate:\n",
        "      generate_images(model, z_random, [0,plots_per_epoch])\n",
        "    plt.plot(epoch_number, test_ELBO, train_ELBO)\n",
        "    plt.legend(['test','train'])\n",
        "    plt.title('model')\n",
        "    plt.show()\n",
        "  train_loss.reset_states()\n",
        "  test_loss.reset_states()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "b4MLsF1E0ebZ"
      },
      "source": [
        "#### Train the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pi8CDE0g0eba",
        "colab": {}
      },
      "source": [
        "x_train_0, y_train_0, x_test_0, y_test_0, train_dataset_0, test_dataset_0 = setup_dataset(x_train, y_train, x_test, y_test, chosen_classes=[0])\n",
        "x_train_1, y_train_1, x_test_1, y_test_1, train_dataset_1, test_dataset_1 = setup_dataset(x_train, y_train, x_test, y_test, chosen_classes=[1])\n",
        "x_train_2, y_train_2, x_test_2, y_test_2, train_dataset_2, test_dataset_2 = setup_dataset(x_train, y_train, x_test, y_test, chosen_classes=[2])\n",
        "x_train_3, y_train_3, x_test_3, y_test_3, train_dataset_3, test_dataset_3 = setup_dataset(x_train, y_train, x_test, y_test, chosen_classes=[3])\n",
        "x_train_4, y_train_4, x_test_4, y_test_4, train_dataset_4, test_dataset_4 = setup_dataset(x_train, y_train, x_test, y_test, chosen_classes=[4])\n",
        "x_train_5, y_train_5, x_test_5, y_test_5, train_dataset_5, test_dataset_5 = setup_dataset(x_train, y_train, x_test, y_test, chosen_classes=[5])\n",
        "x_train_6, y_train_6, x_test_6, y_test_6, train_dataset_6, test_dataset_6 = setup_dataset(x_train, y_train, x_test, y_test, chosen_classes=[6])\n",
        "x_train_7, y_train_7, x_test_7, y_test_7, train_dataset_7, test_dataset_7 = setup_dataset(x_train, y_train, x_test, y_test, chosen_classes=[7])\n",
        "x_train_8, y_train_8, x_test_8, y_test_8, train_dataset_8, test_dataset_8 = setup_dataset(x_train, y_train, x_test, y_test, chosen_classes=[8])\n",
        "x_train_9, y_train_9, x_test_9, y_test_9, train_dataset_9, test_dataset_9 = setup_dataset(x_train, y_train, x_test, y_test, chosen_classes=[9])\n",
        "\n",
        "z_size = 10\n",
        "model_0 = CVAE(z_size)\n",
        "model_1 = CVAE(z_size)\n",
        "model_2 = CVAE(z_size)\n",
        "model_3 = CVAE(z_size)\n",
        "model_4 = CVAE(z_size)\n",
        "model_5 = CVAE(z_size)\n",
        "model_6 = CVAE(z_size)\n",
        "model_7 = CVAE(z_size)\n",
        "model_8 = CVAE(z_size)\n",
        "model_9 = CVAE(z_size)\n",
        "\n",
        "model_dict = {'0' : model_0,\n",
        "              '1' : model_1,\n",
        "\t\t          '2' : model_2,\n",
        "              '3' : model_3,\n",
        "              '4' : model_4,\n",
        "              '5' : model_5,\n",
        "              '6' : model_6,\n",
        "              '7' : model_7,\n",
        "              '8' : model_8,\n",
        "              '9' : model_9,}\n",
        "\n",
        "train_test_dataset(model_0, train_dataset_0, test_dataset_0, 25, generate=True)\n",
        "train_test_dataset(model_1, train_dataset_1, test_dataset_1, 25, generate=True)\n",
        "train_test_dataset(model_2, train_dataset_2, test_dataset_2, 25, generate=True)\n",
        "train_test_dataset(model_3, train_dataset_3, test_dataset_3, 25, generate=True)\n",
        "train_test_dataset(model_4, train_dataset_4, test_dataset_4, 25, generate=True)\n",
        "train_test_dataset(model_5, train_dataset_5, test_dataset_5, 25, generate=True)\n",
        "train_test_dataset(model_6, train_dataset_6, test_dataset_6, 25, generate=True)\n",
        "train_test_dataset(model_7, train_dataset_7, test_dataset_7, 25, generate=True)\n",
        "train_test_dataset(model_8, train_dataset_8, test_dataset_8, 25, generate=True)\n",
        "train_test_dataset(model_9, train_dataset_9, test_dataset_9, 25, generate=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5EO369RTvjX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#x_train_024, y_train_024, x_test_024, y_test_024, train_dataset_024, test_dataset_024 = setup_dataset(x_train, y_train, x_test, y_test, chosen_classes=[0,2,4])\n",
        "#z_size = 2\n",
        "#model_024 = CVAE(z_size)\n",
        "#train_test_dataset(model_024, train_dataset_024, test_dataset_024, 20, generate=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pnr-d-OQZCI5",
        "colab_type": "text"
      },
      "source": [
        "#### Reconstruct images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jz0G3WmQD2vI",
        "colab": {}
      },
      "source": [
        "def reconstruct_images(model, images):\n",
        "    images_n = len(images)\n",
        "    x = images/input_range\n",
        "    x[x >= 0.5] = 1.0\n",
        "    x[x < 0.5] = 0.0\n",
        "    x = x.reshape(images_n, image_shape[0], image_shape[1], N_image_channels).astype('float32')\n",
        "    \n",
        "    z_mean, z_logvar = model.encode(x)\n",
        "    z = model.reparameterize(z_mean, z_logvar)\n",
        "    pixel_output = model.decode(z)\n",
        "    pixel_prob = tf.math.sigmoid(pixel_output)\n",
        "    pixel_prob = np.squeeze(pixel_prob, axis=3)\n",
        "\n",
        "    loss = np.empty([images_n])\n",
        "    for i in range(images_n):\n",
        "        loss[i] = calculate_ELBO(model,x[i:i+1])\n",
        "    loss = loss.astype('float16')\n",
        "    \n",
        "    print('Original Pictures:')\n",
        "    plot_images(images, _, figures_to_plot=[0,images_n], include_labels=False)\n",
        "    print('Reconstructed Pictures, with ELBO loss:')\n",
        "    plot_images(pixel_prob, -loss, figures_to_plot=[0,images_n], include_labels=True)\n",
        "\n",
        "reconstruct_images(model_0, x_test_0[0:10])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8juDbid_YrGS",
        "colab_type": "text"
      },
      "source": [
        "#### Visualize the latent space"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nOgW1CZIjvfG",
        "colab": {}
      },
      "source": [
        "def visualize_latent_space(model, range1, range2, data_x, data_y, a, b):\n",
        "  plot = plt.figure(figsize=[7,7])\n",
        "  outliers=0\n",
        "  for i in range(range1, range2):\n",
        "    pic_visualize = data_x[i]\n",
        "    pic_visualize = pic_visualize.reshape(1, image_shape[0], image_shape[1], N_image_channels).astype('float32')\n",
        "    \n",
        "    z_mean, z_logvar = model.encode(pic_visualize)\n",
        "    z = model.reparameterize(z_mean, z_logvar)\n",
        "    \n",
        "    if any(z_logvar[:,i]>5 for i in range(z_size)):\n",
        "      outliers +=1\n",
        "      continue\n",
        "      \n",
        "    if data_y[i] == 0:\n",
        "      color = 'blue'\n",
        "    if data_y[i] == 1:\n",
        "      color = 'orange'\n",
        "    if data_y[i] == 2:\n",
        "      color = 'green'\n",
        "    if data_y[i] == 3:\n",
        "      color = 'red'\n",
        "    if data_y[i] == 4:\n",
        "      color = 'purple'  \n",
        "    if data_y[i] == 5:\n",
        "      color = 'brown'\n",
        "    if data_y[i] == 6:\n",
        "      color = 'pink'\n",
        "    if data_y[i] == 7:\n",
        "      color = 'gray'\n",
        "    if data_y[i] == 8:\n",
        "      color = 'black'\n",
        "    if data_y[i] == 9:\n",
        "      color = 'yellow'\n",
        "    plt.scatter(z[:,a],z[:,b], color=color, s=10)\n",
        "    #plt.xlim([-1000,1000])\n",
        "    #plt.ylim([-1000,1000])\n",
        "    #plt.annotate('{}'.format(i),(z[:,a],z[:,b]))\n",
        "  print('{} Outliers detected'.format(outliers))\n",
        "\n",
        "\n",
        "visualize_latent_space(model_0, 0,800, x_test_0, y_test_0, 0,1)\n",
        "\n",
        "#labels = []; \n",
        "#for i in range(N_train): labels.append(i)\n",
        "#plot_images(x_train, labels, [250,300])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohcKBv7HYyaS",
        "colab_type": "text"
      },
      "source": [
        "#### Check reconstruction performance for untrained classes\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOUcblcZ4Djo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(0,N_class):\n",
        "  model = model_dict[str(i)]\n",
        "  print('Model trained with class {}'.format(i))\n",
        "  plt.figure(figsize=[9,4])\n",
        "  for j in range(N_class):\n",
        "    test_images = x_test[(y_test==j)]\n",
        "    test_images = set_pixels_binary(test_images)\n",
        "    test_images = test_images.reshape(len(test_images), image_shape[0], image_shape[1], N_image_channels).astype('float32')\n",
        "    loss = -calculate_ELBO(model,test_images)\n",
        "    if j==i:\n",
        "      color='red'\n",
        "    else:\n",
        "      color='blue'\n",
        "    plt.bar(j,-loss.numpy(),color=color)\n",
        "    #print('ELBO loss for class {}: {}'.format(i,loss))\n",
        "  plt.show()\n",
        "  \n",
        "\n",
        "# reconstruct_images(x_test[(y_test==8)][0:10], test_images[(y_test==8)][0:10])\n",
        "\n",
        "#visualize_latent_space(0,1000, x_train, y_train, 0,1)\n",
        "#classes_to_pick = [1]\n",
        "#x_reconstruct_test, y_reconstruct_test = pick_class(x_test, y_test, classes_to_pick)\n",
        "#visualize_latent_space(0,100, x_reconstruct_test, y_reconstruct_test, 0,1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AO32aw-geBRj",
        "colab_type": "text"
      },
      "source": [
        "#### Classify test images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbzrkU3FweFO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_, _, x_test_classes, y_test_classes, _, _ = setup_dataset(x_train, y_train, x_test, y_test, chosen_classes=[0,1,2,3,4,5,6,7,8,9])\n",
        "predicted_class = np.zeros([1,len(x_test_classes)])\n",
        "for i in range(len(x_test_classes)):\n",
        "  if not i%50:\n",
        "    clear_output()\n",
        "    print('Progress:{}%'.format(100*(i+1)/len(x_test_classes)))\n",
        "  test_image = x_test_classes[i]/input_range\n",
        "  test_image[test_image >= 0.5] = 1.0\n",
        "  test_image[test_image < 0.5] = 0.0\n",
        "  test_image = test_image.reshape(1, image_shape[0], image_shape[1], N_image_channels).astype('float32')\n",
        "  \n",
        "  loss_per_model = []\n",
        "  for j in range(0,10):\n",
        "    model = model_dict[str(j)]\n",
        "    loss = -calculate_ELBO(model,test_image)\n",
        "    #print('ELBO loss for class {}: {}'.format(i,loss))\n",
        "    loss_per_model.append(loss)\n",
        "  predicted_class[0,i] = loss_per_model.index(max(loss_per_model))\n",
        "print(predicted_class)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8fLaFXBuzOs",
        "colab_type": "text"
      },
      "source": [
        "#### Check accuracy and plot misslabeled images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsmNgDk3iBDc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "correct_guesses = 0\n",
        "wrong_guesses = []\n",
        "for i,x in enumerate(zip(predicted_class[0,:], y_test_classes)):\n",
        "  if (x[0]==x[1]):\n",
        "    correct_guesses = correct_guesses + 1\n",
        "  else:\n",
        "    wrong_guesses.append(i)\n",
        "\n",
        "total_guesses = len(x_test_classes)\n",
        "accuracy = (correct_guesses/total_guesses)\n",
        "print('Correctly labelled pictures:{}/{} -> Accuracy: {}%'.format(correct_guesses,total_guesses,accuracy*100))\n",
        "print('Incorrectly labelled pictures:{}/{} -> Error: {}%'.format(total_guesses-correct_guesses,total_guesses,(1-accuracy)*100))\n",
        "\n",
        "pics_to_plot = list(x_test_classes[i] for i in wrong_guesses)\n",
        "labels = list(predicted_class[0,i] for i in wrong_guesses)\n",
        "plot_images(pics_to_plot, labels, [0,len(labels)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GV4d1Py2sXEd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convolutional VAE for each class results in accuracy of 98.16% with z_size = 10\n",
        "# Convolutional VAE for each class results in accuracy of 89.90% with z_size = 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v37g0zTrabrK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}