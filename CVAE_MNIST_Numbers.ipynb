{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "CVAE_MNIST_Numbers.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lorenzosintini/4YP/blob/master/CVAE_MNIST_Numbers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "C8VH0HaF0eaI"
      },
      "source": [
        "#### Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "887mv3aj0eaL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1db65555-304e-40c4-f78e-d5c424ba4197"
      },
      "source": [
        "try:\n",
        "    # %tensorflow_version only exists in Colab.\n",
        "    %tensorflow_version 2.x\n",
        "except Exception:\n",
        "    pass\n",
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import time\n",
        "import os\n",
        "import sys"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sUEIvx3I0eaT"
      },
      "source": [
        "#### Import Data (and select part of it only)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tkekihPQ0eaU",
        "outputId": "215bc737-afef-4b0a-be3c-a18a0618b310",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "def pick_class(x_train, y_train, class_n):\n",
        "    new_x_train=x_train[y_train==class_n]\n",
        "    new_y_train=y_train[y_train==class_n]\n",
        "    print(len(new_y_train))\n",
        "    return new_x_train, new_y_train\n",
        "\n",
        "pick_number = True\n",
        "class_to_pick = 2\n",
        "if pick_number:\n",
        "  x_train, y_train = pick_class(x_train, y_train, class_to_pick)\n",
        "\n",
        "#data_inputs = 1000\n",
        "#x_train = x_train[0:data_inputs]\n",
        "#y_train = y_train[0:data_inputs]"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "5958\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lv1qfPcr0eaZ"
      },
      "source": [
        "#### Define Data Size and Classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SXK5XnqV0eab",
        "colab": {}
      },
      "source": [
        "# INPUT DATA\n",
        "class_names = ['Zero','One', 'Two', 'Three', 'Four', 'Five','Six', 'Seven', 'Eight', 'Nine']\n",
        "N_image_channels = 1\n",
        "\n",
        "N_train = len(y_train)\n",
        "N_test = len(y_test)\n",
        "N_class = len(class_names)\n",
        "image_shape = x_train.shape[1:3]\n",
        "input_range = np.amax(x_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BlFAjQiU0eae"
      },
      "source": [
        "#### Plot images from set (random or in order)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "y3udHn4E0eag",
        "outputId": "4bd1a52b-7f91-4cac-8b00-f7ed626cd681",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "source": [
        "def plot_images(x_train, y_train, figures_to_plot=10, pick_random=True):\n",
        "    n_rows = np.ceil(figures_to_plot/10)\n",
        "    plot = plt.figure(figsize=[20,2*n_rows])\n",
        "    for i in range(figures_to_plot):\n",
        "        if pick_random: \n",
        "            pic_n = random.randint(0,len(x_train))\n",
        "        else: pic_n = i\n",
        "        plt.subplot(n_rows,10,i+1)\n",
        "        plt.xticks([]); plt.yticks([])\n",
        "        plt.imshow(x_train[pic_n], cmap=plt.cm.binary)\n",
        "        plt.xlabel(class_names[y_train[pic_n]])\n",
        "    plt.show()\n",
        "\n",
        "plot_images(x_train, y_train, 10, False)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABHEAAAB+CAYAAACj8Y2HAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 1440x144 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "aYGjpOyi0eam"
      },
      "source": [
        "#### Pre-Proces Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EdMZHoBl0ean",
        "outputId": "3b4e6cad-3806-4cd6-bfb6-9ba872b63349",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "source": [
        "train_images = x_train/input_range\n",
        "test_images = x_test/input_range\n",
        "\n",
        "train_images[train_images >= 0.5] = 1.0\n",
        "train_images[train_images < 0.5] = 0.0\n",
        "test_images[test_images >= 0.5] = 1.0\n",
        "test_images[test_images < 0.5] = 0.0\n",
        "\n",
        "train_labels = y_train\n",
        "test_labels = y_test\n",
        "\n",
        "plot_images(train_images, train_labels, 10, False)\n",
        "\n",
        "train_images = train_images.reshape(N_train, image_shape[0], image_shape[1], N_image_channels).astype('float32')\n",
        "test_images = test_images.reshape(N_test, image_shape[0], image_shape[1], N_image_channels).astype('float32')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABHEAAAB+CAYAAACj8Y2HAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
            "text/plain": [
              "<Figure size 1440x144 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qIBflbVS0eas"
      },
      "source": [
        "#### Create Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "S1KptUf00eau",
        "colab": {}
      },
      "source": [
        "batch_size = 100\n",
        "shuffle_size_train = 20000\n",
        "shuffle_size_test = 10000\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_images)).shuffle(shuffle_size_train).batch(batch_size)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_images)).shuffle(shuffle_size_test).batch(batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RXAUM1Hh0ea0"
      },
      "source": [
        "#### Create Variational Autoencoder (VAE) Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oiLqehle0ea2",
        "colab": {}
      },
      "source": [
        "class CVAE(tf.keras.Model):\n",
        "    def __init__(self, z_size):\n",
        "        super(CVAE, self).__init__()\n",
        "        self.z_size = z_size\n",
        "        self.encoder_nn = tf.keras.models.Sequential([ \n",
        "                          tf.keras.layers.InputLayer(input_shape=(28, 28, 1)),\n",
        "                          tf.keras.layers.Conv2D(filters=32, kernel_size=3, strides=(2, 2), activation='relu'),\n",
        "                          tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=(2, 2), activation='relu'),\n",
        "                          tf.keras.layers.Flatten(),\n",
        "                          # No activation\n",
        "                          tf.keras.layers.Dense(z_size*2)\n",
        "                          ])\n",
        "\n",
        "        self.decoder_nn = tf.keras.models.Sequential([\n",
        "                          tf.keras.layers.InputLayer(input_shape=(z_size,)),\n",
        "                          tf.keras.layers.Dense(units=7*7*32, activation=tf.nn.relu),\n",
        "                          tf.keras.layers.Reshape(target_shape=(7, 7, 32)),\n",
        "                          tf.keras.layers.Conv2DTranspose(filters=64, kernel_size=3, strides=(2, 2), padding=\"SAME\", activation='relu'),\n",
        "                          tf.keras.layers.Conv2DTranspose(filters=32, kernel_size=3, strides=(2, 2), padding=\"SAME\", activation='relu'),\n",
        "                          # No activation\n",
        "                          tf.keras.layers.Conv2DTranspose(filters=1, kernel_size=3, strides=(1, 1), padding=\"SAME\")\n",
        "                          ])\n",
        "    @tf.function\n",
        "    def encode(self, x):\n",
        "        encoder_nn_output = self.encoder_nn(x)\n",
        "        z_mean, z_logvar = tf.split(encoder_nn_output, num_or_size_splits=2, axis=1)\n",
        "        return z_mean, z_logvar\n",
        "\n",
        "    def reparameterize(self, z_mean, z_logvar):\n",
        "        eps = tf.random.normal(shape=z_mean.shape)\n",
        "        return eps * tf.exp(z_logvar * 0.5) + z_mean\n",
        "    \n",
        "    def decode(self, z):\n",
        "        pixel_output = self.decoder_nn(z)\n",
        "        pixel_prob = tf.math.sigmoid(pixel_output)\n",
        "        return pixel_prob\n",
        "\n",
        "z_size = 50\n",
        "model = CVAE(z_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ruRl4I4K0ea8"
      },
      "source": [
        "#### Define the loss function "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Y1QqvVSV0ea-",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def compute_loss(model, x):\n",
        "    z_mean, z_logvar = model.encode(x)\n",
        "    z = model.reparameterize(z_mean, z_logvar)\n",
        "    \n",
        "    pixel_prob = model.decode(z)\n",
        "    \n",
        "    logpx_z_pixels = tf.math.log(pixel_prob + 1e-10)*x + tf.math.log(1-pixel_prob + 1e-10)*(1-x)\n",
        "    logpx_z_images = tf.reduce_sum(logpx_z_pixels, axis=[1, 2, 3])\n",
        "    logpx_z = tf.reduce_mean (logpx_z_images)\n",
        "    \n",
        "    kl_parameters = -0.5 * (1 + z_logvar - (z_mean ** 2.0) - tf.exp(z_logvar))\n",
        "    kl_vectors = tf.reduce_sum(kl_parameters, axis=1)\n",
        "    kl = tf.reduce_mean(kl_vectors)\n",
        "    \n",
        "    ELBO = (logpx_z - kl)\n",
        "    \n",
        "    return -ELBO # negative because we want to maximise"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vLIG3YRm0ebE"
      },
      "source": [
        "#### Define the optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "n5eaPpso0ebG",
        "colab": {}
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate = 1e-4) #### why doesn't it work for 1e-3?? ####"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VngH-amb0ebM"
      },
      "source": [
        "#### Calculate the loss function gradients and input these to the optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dNN76Ed_0ebO",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def compute_apply_gradients(model, x, optimizer):\n",
        "    with tf.GradientTape() as tape:\n",
        "        loss = compute_loss(model, x)\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bzdhLrrs0ebT",
        "colab": {}
      },
      "source": [
        "#### Generate random image from latent vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JUG20q7J0ebW",
        "colab": {}
      },
      "source": [
        "z_random = tf.random.normal(shape=[16, z_size])\n",
        "\n",
        "def generate_and_save_images(model, z_random): \n",
        "    generated_prob = model.decode(z_random)\n",
        "    fig = plt.figure(figsize=(4,4))\n",
        "\n",
        "    for i in range(generated_prob.shape[0]):\n",
        "        plt.subplot(4, 4, i+1)\n",
        "        plt.imshow(generated_prob[i, :, :, 0], cmap=plt.cm.binary)\n",
        "        plt.axis('off')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "b4MLsF1E0ebZ"
      },
      "source": [
        "#### Train the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pi8CDE0g0eba",
        "colab": {}
      },
      "source": [
        "epochs = 50\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "    start_time = time.time()\n",
        "    for i, train_x in enumerate(train_dataset): \n",
        "        sys.stdout.write('\\r'+'Epoch {} progress (%): {}'.format(epoch,100*(i+1)/(np.ceil(N_train/batch_size))))\n",
        "        sys.stdout.flush()\n",
        "        compute_apply_gradients(model, train_x, optimizer)\n",
        "    end_time = time.time()\n",
        "\n",
        "    average_loss = 0\n",
        "    for i, test_x in enumerate(test_dataset):\n",
        "        batch_loss = compute_loss(model, test_x)\n",
        "        average_loss = (average_loss*i + batch_loss)/(i+1)\n",
        "    print('\\nTest set ELBO: {}; epoch running time: {}'.format(average_loss, end_time - start_time))\n",
        "    \n",
        "    generate_and_save_images(model, z_random)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "94NCuC4D0ebd",
        "colab": {}
      },
      "source": [
        "#### Reconstruct image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jz0G3WmQD2vI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = train_images[0:1]\n",
        "\n",
        "z_mean, z_logvar = model.encode(x)\n",
        "z = model.reparameterize(z_mean, z_logvar)\n",
        "pixel_output = model.decode(z)\n",
        "pixel_prob = tf.math.sigmoid(pixel_output)\n",
        "\n",
        "loss = compute_loss(model,x)\n",
        "print(loss.numpy())\n",
        "\n",
        "fig = plt.figure(figsize=(5,5))\n",
        "plt.imshow(x[0,:, :, 0], cmap=plt.cm.binary)\n",
        "plt.show\n",
        "\n",
        "fig = plt.figure(figsize=(5,5))\n",
        "plt.imshow(pixel_prob[0,:, :, 0], cmap=plt.cm.binary)\n",
        "plt.show"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZIPxg1jGsAC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}